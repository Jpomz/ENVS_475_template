<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>LECTURE 05: Estimation</title>
    <meta charset="utf-8" />
    <meta name="author" content="   Spring 2023" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# LECTURE 05: Estimation
]
.subtitle[
## ENVS475: Exp. Design and Analysis
]
.author[
### <br/><br/><br/>Spring 2023
]

---




class: inverse

# Outline

&lt;br/&gt;
#### 1) Descriptive Statistics

&lt;br/&gt;  

#### 2) Inferential Statistics

&lt;br/&gt; 

#### 3) Confidence Intervals

&lt;br/&gt; 

---
# Review: populations vs samples

#### Population  
- A collection of subjects of interest  

- Often, a biologically meaningful unit  

- Sometimes a process of interest  

#### Sample

- A finite subset of the population of interest, i.e. the data we collect  

- Samples allow us to draw inferences about the population  

- Good samples are:
    + Random  
    + Representative  
    + Sufficiently large  

---

# Review: parameters vs statistics

### Parameters 
- Attributes of the population  
  + Mean ( `\(\mu\)` )  
  + Variance ( `\(\sigma^2\)` )  
  + Standard deviation ( `\(\sigma\)` )  
- Parameters are the quantities of interest, and usually unknown  

--
### Statistics
- Attributes of the sample  
  + Mean ( `\(\bar{y}\)` or `\(\hat{\mu}\)` )  
  + Variance ( `\(s^2\)` or `\(\hat{\sigma}^2\)` )  
  + Standard deviation ( `\(s\)` or `\(\hat{\sigma}\)` )  
- Often treated as estimates of parameters
---

class: inverse, center, middle
# Descriptive Statistics

---
# Descriptive Statistics

### Measures of central tendency

- **Sample mean**

`$$\large \bar{y} = \frac{\sum_{i=1}^n y_i}{n}$$`

&lt;br/&gt;

--
- **Median**: "middle" of the data  

  + 50% of data is below, 50% of data is above median  
  
  + Useful for non-normal, or skewed data  
  
  + If data is truly normal, mean = median  
  

&lt;br/&gt;
--

- **Mode**: Most frequent observation in the data

---

### Central Tendency Example:

* Weight of Wolves (kg) from Yellowstone:
`40, 35, 32, 37, 35, 37, 35, 35`

&lt;br/&gt;

* Mean (rounded): 35.6  
  * `mean()`

&lt;br/&gt;

* Median (rounded): 35.2  
  * `median()`  

&lt;br/&gt;

* Mode: 35  
  * no default in function in R  
  * For small data sets, `sort()` vector and count repeats
  * 32, 35, 35, 35, 35, 37, 37, 40  

---

### Measures of dispersion

- Sample variance  
  - How far, on average, are the *observations* from the mean?  
  - squared scale - different from data

`$$\large s^2 = \frac{\sum_{i=1}^n (y_i - \bar{y})^2}{n-1}$$`

&lt;br/&gt;

--
- Sample standard deviation  
  - How far, on average, are the *observations* from the mean?  
  - same scale as data

`$$\large s = \sqrt{s^2}$$`

&lt;br/&gt;

--
- Range  
  * min and max values of data

---
### Dispersion Example:

* Weight of Wolves (kg) from Yellowstone:
`40, 35, 32, 37, 35, 37, 35, 35`

&lt;br/&gt;

* Variance: 5.4  
  * `var()`  
  * Remember, different scale!

&lt;br/&gt;

* Standard Deviation: 2.3  
  * `sd()`  
  * same scale as data  
  * SD is mostly what we will use  

&lt;br/&gt;

* Range: 32, 40  
  * `range()`  
---
# Describing the sample  

* When describing the data, always include the mean and a measure of dispersion  

  + be sure to label measure of dispersion (var or SD?)
  
&gt; The weight of Yellowstone wolves is 35.6 `\(\pm\)` 2.3 kg (mean `\(\pm\)` SD)  

* Alternate:  

&gt; The average ( `\(\pm\)` SD)  weight of wolves in Yellowstone is 35.6 `\(\pm\)` 2.3 kg 

---
# Inferential Statistics

* So far, we've been discussing *descriptive statistics* for our observations  

* Analyses often interested in comparing means, or estimates of `\(\mu\)`.  

* This requires *inferential statistics*  
---
# Inferential Statistics

* Weight of Wolves (kg) from Yellowstone:
`40, 35, 32, 37, 35, 37, 35, 35`
* Mean: 35.6  
* SD: 2.3  

&lt;br/&gt;
### How confident are we in this value?  
* If we measured another 8 wolves, what would our estimates be?  

* 2nd Sample: `33, 28, 40, 43, 35, 31, 40, 42` 
* 2nd Mean: 36.8  
* 2nd SD: 5.5  

---

# Inferential Statistics
### Standard error of the mean: SEM  

&lt;br/&gt;

* How far, on average, is the sample mean `\(\bar{y}\)` from the true mean `\(\mu\)`?  

&lt;br/&gt;

* We could repeat experiment over and over again to get a *sampling distribution*  

&lt;br/&gt;

  * Rarely done due to time, logistics, funding, etc.  
  
&lt;br/&gt;

* Luckily, we can estimate the SEM from a single sample

---
# Inferential Statistics
### Standard error of the mean: SEM  

`$$\Large SEM = \frac{s}{\sqrt{n}}$$`
&lt;br/&gt;

* Remember, SEM tells us how far, on average, the sample mean `\(\bar{y}\)` is from the true mean `\(\mu\)`  

* SEM is like a standard deviation *of the mean*


---
### Helpful(?) mnemonic 

&lt;br/&gt;

* SD: dispersion for the data (**D**)  

  * How far is an individual observation from the sample mean?  

&lt;br/&gt;

* SEM: dispersion for the mean (**M**)  

  * How far is the sample mean from the true mean?  

&lt;br/&gt;

  * Note that SEM is sometimes just abbreviated as SE, so this mnemonic isn't always obvious. 
  
---
### Point estimates  

* `\(\bar{y}\)` is a point estimate of the true mean, `\(\mu\)`  
* point estimates on their own are of limited value  

* Always include a measure of precision when you report a mean

`$$\Large \bar{y} \pm SEM$$`

--

#### Wolf sample 1:  
* Mean: 35.6
* SEM: 0.8  

--

`\(35.6 \pm 0.8\)` (mean `\(\pm\)` SEM)

--

* Note similarity with sample description previously  

--

  * Always label your dispersion estimate! 

--

* You can also present the interval by completing the equation:

* Interval = `(34.8, 36.4)`

---

class: inverse, center, middle
# Confidence Intervals

---
# Confidence Intervals  
- Confidence Intervals (CI) is a range of estimates for an unknown parameter.  
- CI computed for different confidence levels: most often 95%  
- Assuming a normal distribution, 95% CI is approximately:

`$$\Large 95\%CI =\bar{y} \pm 2*SEM$$`  

  + Recall empirical rule: 95% of data within `\(\pm 2~SD\)`  
  
  + In future classes we will discuss equation for CI from a *t*-distribution, i.e., modify value of 2 in above equation    

- If we calculated a 95% CI from `\(n\)` samples, about 95% of them would contain the true population mean  

  + **NOTE** it *does not mean* that we are 95% sure that the true mean is in the CI  
  
---

### Repeated samples from Population  
- 100 repeated samples of wolf weights  
- Increased to 25 wolves per sample  

&lt;img src="lecture_05_estimation_files/figure-html/CI-plot-1.png" width="648" style="display: block; margin: auto;" /&gt;

* 97 / 100 CIs contain true mean ~97%  
---

### Using Confidence Intervals to test hypotheses  

* Previous research has indicated that mean wolf weight in the Arctic is 33 kg.  

* Does this differ from the wolves in Yellowstone?  

* CI for Yellowstone wolf weight (1st sample)  

`$$95\%CI =\bar{y} \pm 2*SEM$$`  

&lt;br/&gt;

`$$35.6 \pm 2 * 0.8 = (34,~37.2)$$`

* Arctic weight of 33 is outside (below) 95% CI for Yellowstone wolves.  

* **Interpretation**: The data support the conclusion, with 95% confidence, that the weight of Yellowstone Wolves is between 34 and 37.2 kg, and this is higher than the mean estimated weight for wolves in the Arctic of 33 kg. 

---
### Changing the Confidence Interval  

* We can approximate a 99% CI by multiplying the SEM by 3

`$$99\%CI =\bar{y} \pm 3*SEM$$` 

`$$35.6 \pm 3 * 0.8 = (33.2,~38)$$`

* How does the 99% CI compare with the 95% CI?  
  + *i.e.*, which is wider and narrower?  
  + Why do you think this is?  
  
---

### Using Confidence Intervals to test hypotheses  

* Data from British Columbia indicates that the mean weight of wolves there is 34.2 kg.  

--

* Do the weight of wolves in BC differ from those in Yellowstone?  

--

* 34.2 falls within the 95% CI (34, 37.2) for Yellowstone Wolves.

--

* **Interpretation**: The data support the conclusion that the weight of Yellowstone Wolves is between 34 and 37.2 kg (95% CI), and that this is not different from the mean estimated weight of 34.2 for wolves in British Columbia.  

--

* Note we did not use CI's for Arctic or BC wolves.  
  
  * Using CI's is one form of (rough) hypothesis testing  
  
  * We can more formally test these hypotheses with t-test and general linear models  
  
  * We will get to this later in the course.  

---


# Looking ahead

### **Wednesday**: Point estimates and CI Lab

&lt;br/&gt;

### **Friday**: Hw 05 - For a grade

&lt;br/&gt;

### **Reading**: Hector Chapter 5

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
