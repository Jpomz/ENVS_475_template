---
title: "Lab 08: t-tests"
subtitle: "ENVS475: Experimental Analysis and Design"
date: "Spring, 2023"
output: 
  html_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
bt_samp <- read.csv(here::here("data/body_temp_hr.csv"))
```

## About

This lab will explore formal hypothesis testing by considering classic t-tests from a linear modelling perspective.  

## Preliminaries 

### Packages  

For this lab, we will be using the `dplyr` and `ggplot2` packages. Make sure both packages are installed on your computer, and then run the following code:

```{r, eval=FALSE}
library(dplyr)
library(ggplot2)
```


### Data  

For this lab, we will be creating data sets in R. No data needs to be downloaded or read in to R. 

# One sample t-test: Stream pH  

You may expect that streams around Grand Junction should have an approximately neutral pH of 7. Let's look at some simulated data and formally tests whether or not the average stream pH is significantly different from 7. Here, the value of interest is $\mu_0 = 7$  

## Formal Hypotheses  

We can state our hypotheses formally using Null and Alternatives as follows:

$$H_0: \mu = 7$$
$$H_A: \mu \ne 7$$

Since our Alternative hypothesis is $\ne$ this is a 2-tailed test. In other words we have to account for the fact that pH could be higher or lower than our null value of 7.  


We can express this as a simple linear model:  

$$y_i = \mu + \epsilon_i$$
where $y_i$ is a single observation of stream pH, $\mu$ is the population mean, and $\epsilon_i$ is the deviation from the expected value. Further, we expect the deviations to be distributed normally:

$$\epsilon \sim N(0, \sigma)$$

## Analysis: Manual   

Let's look at some simulated data, and load it into R as a vector. 

```{r}
# simulated data values
y <- c(6.2, 6.8, 7.3, 6.4, 6.3)
```

For the one-sample t-test, we will calculate all necessary variables manually, and then compare it to using the `lm()` function.  

Recall that we calculate a one-sample t-statistic with the following:

$$t_{statistic} =\frac{\bar{y} - \mu_{0} }{SEM_y}$$

Where $\bar{y}$ is the mean, $\mu_0$ is the value of interest (pH = 7) and $SEM$ is calculated as $s / \sqrt(n)$. Let's calculate these values in R and store them as objects. 

```{r}
y_bar <- mean(y)
y_bar
mu_0 <- 7
mu_0
y_sd <- sd(y)
y_sd
y_sem <- y_sd / sqrt(length(y))
y_sem
```

Now let's calculate the t-statistic

```{r}
t_stat <- (y_bar - mu_0) / y_sem
t_stat
```

Now we need to calculate the t-critical value for this t-distribution. We can use the `qt()` function. This is similar to the `qnorm()` function we used previously for the normal distribution, but now we are looking at the t-distribution. for `qt()`, we need to supply the quantile (0.025) and the degrees of freedom (df = n - 1 = 4). The standard $\alpha$ value is 0.05, but since this is a 2-tailed test we have to divide it by 2 (hence 0.025) in order to account for both tails. 

```{r}
t_crit <- qt(0.025, df = 4)
round(t_crit, 2)
```

Is our `t_stat` value $\ge$ our critical value? Note that we are going to use the absolute values so that we do not need to worry about using the proper > or < with negative numbers. 

```{r}
abs(t_stat) > abs(t_crit)
```

It is not, so we would fail to reject our null hypothesis. We can also calculate a p-value for our `t_critical` value by using the `pt()` function. We first calculate the probability of observing out `t_stat`, and then multiply it by 2 since this is a 2-tailed test. Also, we are going to use the absolute value of our `t_stat` and set the `lower.tail = FALSE` argument within `pt()`. This ensures that we don't need to worry about mixing up our + and - signs when calculating a p-value.  

```{r}
one_samp_p_val <- pt(abs(t_stat), df = 4, lower.tail = FALSE) * 2
one_samp_p_val
```

## Interpretation  

Based on our data, we fail to reject the null hypothesis that stream pH is equal to 7 ($t_{statistic} = -1.96, df = 4, p = 0.12$)

## Analysis: using `lm()`

We can use the `lm()` function to automatically calculate our values and test the hypothesis formally. 

Recall that `y` is our observations of data, and our null value is 7. When we run a one-sample t-test in `lm()`, we have to subtract the value of interest from our data. Review the numerator in the formula for the one-sample t-statistic above. 

```{r}
one_sample_fit <- lm(y - mu_0 ~ 1)
summary(one_sample_fit)
```

We can also reprint the values we calculated by hand and locate them in the output table (note that we are subtracting mu_0 from y_bar to put it on the same scale as our `(Intercept)` estimate in the table):

```{r}
y_bar - mu_0
y_sd
y_sem
t_crit
one_samp_p_val
```

### **You should now be able to complete problem 1 in the homework assignment**

# Two-sample t-tests: Tree Densities  

Is the density of trees at high elevations different from low elevations?

$$H_0: \mu_{high} = \mu_{low}$$
$$H_A: \mu_{high} \ne \mu_{low}$$
## Data

We will make a data.frame of the data and call it `tree`. 

```{r}
tree <- data.frame(
  elevation = rep(c("Low", "High"), each = 10),
  dens = c(16, 14, 18, 17, 29, 31, 14, 16, 22, 15, 2, 11, 6, 8, 0, 3, 19, 1, 6, 5))
```

Calculate statistics with dplyr. Recall that for a two-sample t-test we need the:

$$\large t = \frac{\bar{y}_1 -\bar{y}_2}{SEDM}$$
Where SEDM:

$$\large SEDM = \sqrt{SEM_1^2 + SEM^2_2}$$

And that the $SEM_i$ is caluclated as:

$$\large SEM_i = \frac{s}{\sqrt(n)}$$

To summarize, we need the `mean()`, `sd()` and `sqrt(n())` for each `elevation` group in the data. 

```{r}
tree_summary <- tree %>%
  group_by(elevation) %>%
  summarise(mean_density = mean(dens),
            sd_density = sd(dens),
            sqrt_n = sqrt(n())) %>%
  mutate(sem = sd_density / sqrt_n) %>%
  # change it from a tibble to a data.frame to make
  # next steps easier
  as.data.frame()
tree_summary
```


Unfortunately there is not an easy way to calculate the t-statistic using `dplyr`, so we will need to extract the variables individually (when we use the `lm()` all of these steps are automated, but we will continue to calculate it manually so you can see the process). We will use the `data_object[row_number,column_number]` function to subset the values into new variables. This is also why we converted `tree_summary` into a data.frame. 

```{r}
y_high <- tree_summary[1,2]
y_high
y_low <- tree_summary[2,2]
y_low
sem_high <- tree_summary[1,5]
sem_high
sem_low <- tree_summary[2,5]
sem_low
```

```{r}
t_stat_trees <- (y_low - y_high) / sqrt(sem_high^2 + sem_low^2)
t_stat_trees
```

Now that we have a t-statistic, we need to calculate our t-critical value to compare it with and decide if we can formally rejct or fail to reject our null hypothesis. To calculate the t-critical value, we will once again use `qt()` funciton. Our degrees of freedom here is 18 (total n = 20, but we need to subtract 1 for each group: 20 - (1 + 1) = 18).  

```{r}
t_crit_trees <- qt(0.025, df = 18)
t_crit_trees
```

To compare our t-critical and t-statistic, we will once again use the absolute values to avoid mixing up our signs. 

```{r}
abs(t_stat_trees) > abs(t_crit_trees)
```

```{r}
two_samp_p_val <- pt(abs(t_stat_trees), df = 18, lower.tail = FALSE) * 2
two_samp_p_val
```
 
When you have a really low p-value like this, it's best to round instead of reporting the full value. Reporting the exact value adds a false sense of specificity. The three levels of significance are generally p < 0.05, p < 0.01, and p < 0.001. Here we would just say that the p-value is < 0.001. 
 
 ### Interpretation  
 
Based on the data, we can reject the null hypothesis and accept the alternative that tree densities are not equal at different elevations ($t_{statistic} = 4.97, df = 18, p < 0.001$). 

## 2-sample t-test using `lm()`  

The hand calculations for a 2-sample t-test are tedious. Luckily we can run the same analysis in just a few lines of code using the `lm()` function. 

```{r}
two_sample_fit <- lm(dens ~ elevation, data = tree)
summary(two_sample_fit)
```

### **You should now be able to complete problem 2 in the homework assignment**
 
# Paired t-tests: Herbicide Treatments

## Data

For this section of the lab, you will need to download the `caterpillar.csv` file from D2L. 

```{r, eval=FALSE}
caterpillar <- read.csv("data/caterpillar.csv")
```

For a paired t-test, the null hypothesis is that the avergae difference between the two groups is 0. 

$$H_0:\large \mu_D = 0$$
$$H_A:\large \mu_D \ne 0$$

For this, we need to calculate the difference between the two treatments. If we look at the way the data is organized, there is not a simple solution using `dplyr` functions. 

```{r}
caterpillar
```
Luckily, there is a special helper function called `diff()` that we can use inside of `mutate()`. First, we need to group the data so that it uses the correct numbers. Here, we want to know what the difference is between `treatment` groups *within* each `plot_number`. So we will use `group_by(plot_number)`. 

```{r}

```

